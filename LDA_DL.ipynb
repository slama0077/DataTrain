{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import LoadData as ld\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import mne\n",
    "from time import perf_counter\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def createEpoch(feature_data, epoch_size, epoch_window):\n",
    "    '''\n",
    "    this creates epoch for CSP data which will be lateer\n",
    "    used for LDA\n",
    "    '''\n",
    "    epochs = []\n",
    "    n_samples = feature_data.shape[1]\n",
    "    for i in range(0, n_samples, epoch_window):\n",
    "        if n_samples - i < epoch_size:\n",
    "            break\n",
    "\n",
    "        epoch_data = feature_data[:, i: i + epoch_size]\n",
    "        epochs.append(epoch_data)\n",
    "    \n",
    "    \n",
    "    epochs_array = np.array(epochs)\n",
    "\n",
    "    return epochs_array\n",
    "\n",
    "\n",
    "\n",
    "def createChannelInfo(no_channels):\n",
    "    '''This function creates an info object \n",
    "    that is required later to convert the eeg data from np data\n",
    "    to mne.io.raw data.\n",
    "\n",
    "    no_channels: number of channels used in the eeg data\n",
    "\n",
    "    returns info object\n",
    "    '''\n",
    "    ch_names = []\n",
    "    for i in range(no_channels):\n",
    "        ch_names.append('Channel' +\"-\"+ str(i))   #for this code I have just created dummy channel names. We can have actual channel names\n",
    "    info = mne.create_info(ch_names = ch_names, sfreq = 250, ch_types='eeg') \n",
    "    return info \n",
    "\n",
    "def bandPassFilterReshape(raw_data, info):\n",
    "    '''\n",
    "    First converts the np data into mne.io.raw data and\n",
    "    uses createEpoch funcn to convert the data into epochs\n",
    "    raw_data : eeg data\n",
    "    info: info object we created before which has information about the channel\n",
    "    \n",
    "    returns epoch data which will be applied for CSP\n",
    "    '''\n",
    "    raw_data = np.transpose(raw_data)\n",
    "    features = mne.io.RawArray(raw_data, info)\n",
    "    features.filter(7.0, 40.0)\n",
    "    features_data = features.get_data()\n",
    "    # features_data = np.transpose(features_data)\n",
    "    features_data = createEpoch(features_data, 250, 64)\n",
    "    return features_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file name provided is correct. Thank you!\n",
      "The file name provided is correct. Thank you!\n",
      "The file name provided is correct. Thank you!\n",
      "The file name provided is correct. Thank you!\n",
      "Creating RawArray with float64 data, n_channels=22, n_times=51750\n",
      "    Range : 0 ... 51749 =      0.000 ...   206.996 secs\n",
      "Ready.\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 7 - 40 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 7.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 6.00 Hz)\n",
      "- Upper passband edge: 40.00 Hz\n",
      "- Upper transition bandwidth: 10.00 Hz (-6 dB cutoff frequency: 45.00 Hz)\n",
      "- Filter length: 413 samples (1.652 s)\n",
      "\n",
      "Creating RawArray with float64 data, n_channels=22, n_times=51750\n",
      "    Range : 0 ... 51749 =      0.000 ...   206.996 secs\n",
      "Ready.\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 7 - 40 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 7.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 6.00 Hz)\n",
      "- Upper passband edge: 40.00 Hz\n",
      "- Upper transition bandwidth: 10.00 Hz (-6 dB cutoff frequency: 45.00 Hz)\n",
      "- Filter length: 413 samples (1.652 s)\n",
      "\n",
      "Creating RawArray with float64 data, n_channels=22, n_times=52500\n",
      "    Range : 0 ... 52499 =      0.000 ...   209.996 secs\n",
      "Ready.\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 7 - 40 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 7.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 6.00 Hz)\n",
      "- Upper passband edge: 40.00 Hz\n",
      "- Upper transition bandwidth: 10.00 Hz (-6 dB cutoff frequency: 45.00 Hz)\n",
      "- Filter length: 413 samples (1.652 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating RawArray with float64 data, n_channels=22, n_times=53250\n",
      "    Range : 0 ... 53249 =      0.000 ...   212.996 secs\n",
      "Ready.\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 7 - 40 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 7.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 6.00 Hz)\n",
      "- Upper passband edge: 40.00 Hz\n",
      "- Upper transition bandwidth: 10.00 Hz (-6 dB cutoff frequency: 45.00 Hz)\n",
      "- Filter length: 413 samples (1.652 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n"
     ]
    }
   ],
   "source": [
    "raw_data_hand = ld.loadData()   \n",
    "raw_data_feet = ld.loadData()    #loading eeg data of any two movements of ur choosing\n",
    "\n",
    "test_data_hand = ld.loadData()\n",
    "test_data_feet = ld.loadData() \n",
    "\n",
    "info = createChannelInfo(22)     #we will need the info object to convert the eeg data from np data to raw_eeg data which we will need for bandpass filtering\n",
    "\n",
    "features_hand = bandPassFilterReshape(raw_data_hand, info)   #this converts the eeg data into epochs, which will be needed for CSP\n",
    "features_feet = bandPassFilterReshape(raw_data_feet, info)\n",
    "\n",
    "features_test_hand = bandPassFilterReshape(test_data_hand, info)\n",
    "features_test_feet = bandPassFilterReshape(test_data_feet, info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "features =  np.concatenate((features_hand, features_feet))\n",
    "label = np.concatenate((np.zeros(features_hand.shape[0]),np.ones(features_feet.shape[0])))\n",
    "\n",
    "features_test =  np.concatenate((features_test_hand, features_test_feet))\n",
    "label_test = np.concatenate((np.zeros(features_test_hand.shape[0]),np.ones(features_test_feet.shape[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing rank from data with rank=None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Using tolerance 53 (2.2e-16 eps * 22 dim * 1.1e+16  max singular value)\n",
      "    Estimated rank (mag): 22\n",
      "    MAG: rank 22 computed from 22 data channels with 0 projectors\n",
      "Reducing data rank from 22 -> 22\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 53 (2.2e-16 eps * 22 dim * 1.1e+16  max singular value)\n",
      "    Estimated rank (mag): 22\n",
      "    MAG: rank 22 computed from 22 data channels with 0 projectors\n",
      "Reducing data rank from 22 -> 22\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "csp = mne.decoding.CSP(n_components = 21, reg = None, log = True, norm_trace = False)\n",
    "features_transform = csp.fit_transform(features, label)\n",
    "features_test_transform = csp.transform(features_test)\n",
    "lda = LinearDiscriminantAnalysis()    #creating LDA classifier (we can specify the dimension, but if only two movements are classified, it is going to be automatically 1 dimension)\n",
    "lda_transform = lda.fit_transform(features_transform, label)\n",
    "lda_transform_test = lda.transform(features_test_transform)\n",
    "lda_transform = np.reshape(lda_transform, (lda_transform.shape[0]))\n",
    "lda_transform_test = np.reshape(lda_transform_test, (lda_transform_test.shape[0]))\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((lda_transform, label))\n",
    "dataset = dataset.shuffle(buffer_size= lda_transform.shape[0]).batch(32)\n",
    "\n",
    "dataset_test = tf.data.Dataset.from_tensor_slices((lda_transform_test, label_test))\n",
    "dataset_test = dataset_test.shuffle(buffer_size = lda_transform_test.shape[0]).batch(32)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">258</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m16,512\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m16,512\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │           \u001b[38;5;34m258\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">33,538</span> (131.01 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m33,538\u001b[0m (131.01 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">33,538</span> (131.01 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m33,538\u001b[0m (131.01 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "input = keras.Input(shape=(1,))\n",
    "\n",
    "hl1 =  keras.layers.Dense(128, activation= keras.layers.LeakyReLU(0.3))(input)\n",
    "\n",
    "hl2 = keras.layers.Dense(128, activation= keras.layers.LeakyReLU(0.3))(hl1)\n",
    "\n",
    "hl3 = keras.layers.Dense(128, activation = keras.layers.LeakyReLU(0.3)) (hl2)\n",
    "\n",
    "\n",
    "output = keras.layers.Dense(2, activation = \"softmax\")(hl3)\n",
    "\n",
    "\n",
    "model =  keras.Model(input, output)\n",
    " \n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", loss = \"sparse_categorical_crossentropy\", metrics = [\"accuracy\"])\n",
    "\n",
    "model.fit(dataset, epochs = 50, validation_data = dataset_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
